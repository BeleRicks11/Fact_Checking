{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GM9DBN-Qz3k"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Fact checking, Neural Languange Inference (**NLI**)\n",
        "\n",
        "**Authors**: \n",
        "\n",
        "*   Davide Mercanti: davide.mercanti@studio.unibo.it\n",
        "*   Riccardo Fava: riccardo.fava6@studio.unibo.it\n",
        "*   Luca Bompani: luca.bompani4@studio.unibo.it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oXJl-V9jCflb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e587165-526a-4a35-c85f-83d1851b822a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.8.1-py2.py3-none-any.whl (208 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3121946 sha256=fa3ab8f7ed879f0144a9e0936862565e96e2c0b97eeccb6e863c82cf8abcf3f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.8.1\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (0.70.12.2)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess) (0.3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n",
        "!pip install multiprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qMuI-qQv7ix0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65d9c69-bb4f-40dc-c024-793dce2d8782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH = '/content/drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/UniBO/NLP/Assignent_2/util.py ."
      ],
      "metadata": {
        "id": "eddiy55rpB7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A4u47cS5CU4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42775da0-6798-45b9-babe-fec6e8ffe4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from enum import Enum\n",
        "import time, string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "from functools import reduce\n",
        "import re,sys,os\n",
        "import contextlib\n",
        "\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import tensor\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.functional import pad\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "import multiprocess as mp  # =! multiprocessing\n",
        "\n",
        "from util import *\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9MMcBsiCDpcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeea5ab8-dbcf-4777-a7a5-56bf80627c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading FEVER data splits...\n",
            "Download completed!\n",
            "Extracting dataset...\n",
            "Extraction completed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(data_path):\n",
        "    toy_data_path = os.path.join(data_path, 'fever_data.zip')\n",
        "    toy_data_url_id = \"1wArZhF9_SHW17WKNGeLmX-QTYw9Zscl1\"\n",
        "    toy_url = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "\n",
        "    if not os.path.exists(toy_data_path):\n",
        "        print(\"Downloading FEVER data splits...\")\n",
        "        with requests.Session() as current_session:\n",
        "            response = current_session.get(toy_url,\n",
        "                                   params={'id': toy_data_url_id},\n",
        "                                   stream=True)\n",
        "        save_response_content(response, toy_data_path)\n",
        "        print(\"Download completed!\")\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(toy_data_path) as loaded_zip:\n",
        "            loaded_zip.extractall(data_path)\n",
        "        print(\"Extraction completed!\")\n",
        "\n",
        "download_data('dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA9nfgHICU4u"
      },
      "source": [
        "## Dataset pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gr4RKHVCU4v"
      },
      "source": [
        "### Dataset loading and inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k5n5uFlOCU4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e6eadac6-2040-4269-9788-77b71569a56e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"10\\tThe island 's geography comprises relatively low-lying mountains surrounding a central plain , with several navigable rivers extending inland .\\tisland\\tisland\\tgeography\\tgeography\\tseveral navigable rivers\\tRivers of Ireland\""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "TRAIN_DF = pd.read_csv(f\"dataset/train_pairs.csv\")\n",
        "TEST_DF  = pd.read_csv(f\"dataset/test_pairs.csv\")\n",
        "VALID_DF = pd.read_csv(f\"dataset/val_pairs.csv\")\n",
        "\n",
        "TRAIN_DF[\"Evidence\"][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "erpnIhMxCU4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3d7615-e25b-41ef-bec6-34ce17df2698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords download\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    STOPWORDS = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    print('stopwords download')\n",
        "    nltk.download('stopwords')\n",
        "    STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    '''Applies a list of pre-processing functions in sequence (reduce).'''\n",
        "    \n",
        "    def remove_stopwords(sentence):\n",
        "        return ' '.join([word for word in sentence.split() if word not in (STOPWORDS)])\n",
        "\n",
        "    def lower(text) :\n",
        "        return text.lower()\n",
        "\n",
        "    def convert_round_brackets(text) :\n",
        "        # convert -LRB- -RRB- to ( or )\n",
        "        pattern = r'-LRB-'\n",
        "        text = re.sub(pattern, '(', text)\n",
        "        pattern = r'-RRB-'\n",
        "        return re.sub(pattern, ')', text)\n",
        "\n",
        "    def fix_double_dashes(text) :\n",
        "        # fix: double dashes (--)\n",
        "        pattern = r'\\-\\-'\n",
        "        return re.sub(pattern, '-', text)\n",
        "\n",
        "    def remove_leading_tabs(text) :\n",
        "        # remove leading tabs\n",
        "        pattern = r'[0-9]+?\\t'\n",
        "        return re.sub(pattern, '', text)\n",
        "\n",
        "    def remove_pronunciations(text) :\n",
        "        # remove pronunciations\n",
        "        pattern = r'-LSB-.*?-RSB-(\\s;)*?'\n",
        "        return re.sub(pattern, '', text)\n",
        "\n",
        "    def remove_trailing_tags(text):\n",
        "        pattern=r'.\\t.*?$'\n",
        "        return re.sub(pattern, '', text)\n",
        "    \n",
        "    def trailing_tags(text):\n",
        "        return re.sub('\\t', ' ', text)\n",
        "\n",
        "    def split_periods(text) :\n",
        "        pattern = r'(\\s.+?)\\.'\n",
        "        return re.sub(pattern, r'\\1 .', text)\n",
        "\n",
        "    def fix_days(text) :\n",
        "        # fix: 31st -> 31 st\n",
        "        pattern = r'([0-9]{1,2})(st|nd|rd|th)'\n",
        "        return re.sub(pattern, r'\\1', text)\n",
        "\n",
        "    def separate_years(text) :\n",
        "        # separate years from other words\n",
        "        pattern = r'(\\s.+?)([0-9]{4})'\n",
        "        return re.sub(pattern, r'\\1 \\2', text) \n",
        "\n",
        "    def fix_years_ranges(text) :\n",
        "        # fix years ranges\n",
        "        pattern = r'([0-9]{4})\\-([0-9]{4})'\n",
        "        text = re.sub(pattern, r'\\1 - \\2', text)\n",
        "        pattern = r'([0-9]{2})([0-9]{2})\\-([0-9]{2})'\n",
        "        text = re.sub(pattern, r'\\1\\2 - \\1\\3', text)\n",
        "        pattern = r'\\'([0-9]{2})-\\'([0-9]{2})'\n",
        "        return re.sub(pattern, r'19\\1 - 19\\2', text)\n",
        "\n",
        "    def fix_number_ranges(text) :\n",
        "        # fix: numbers ranges\n",
        "        pattern = r'([0-9]+?[,\\.][0-9]+?)+?-([0-9]+?[,\\.][0-9]+?)+'\n",
        "        return re.sub(pattern, r'\\1 - \\2', text)\n",
        "\n",
        "    def fix_double_tick(text) :\n",
        "        # fix: double tick\n",
        "        pattern = r'\\`\\`'\n",
        "        return re.sub(pattern, '\"', text)\n",
        "\n",
        "    def fix_date_merged(text) :\n",
        "        # fix: year/day merged with other word\n",
        "        pattern = r'([0-9]{1,4})([a-zA-Z]+?)'\n",
        "        return re.sub(pattern, r'\\1 \\2', text)\n",
        "\n",
        "    def remove_round_brackets(text) :\n",
        "        # remove between round brackets\n",
        "        pattern = r'\\([^\\(\\)]+?\\)'\n",
        "        return re.sub(pattern, ' ', text)\n",
        "\n",
        "    def remove_double_spaces(text) :\n",
        "        # remove double spaces\n",
        "        pattern = r'(\\s)\\s+?'\n",
        "        return re.sub(pattern, r'\\1', text)\n",
        "    \n",
        "    preprocessing_pipeline = [\n",
        "                          remove_leading_tabs,\n",
        "                          #remove_trailing_tags,\n",
        "                          trailing_tags,\n",
        "                          remove_stopwords,\n",
        "                          convert_round_brackets,\n",
        "                          #remove_round_brackets,\n",
        "                          remove_pronunciations,\n",
        "                          fix_double_dashes,\n",
        "                          split_periods,\n",
        "                          fix_days,\n",
        "                          separate_years,\n",
        "                          fix_years_ranges,\n",
        "                          fix_number_ranges,\n",
        "                          fix_double_tick,\n",
        "                          fix_date_merged,\n",
        "                          remove_double_spaces,\n",
        "                          lower]\n",
        "    \n",
        "    return reduce(lambda txt, f: f(txt), preprocessing_pipeline, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bffqfeg5CU42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be12f83-004b-472b-adac-7aa37d038718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before the cleaning:\n",
            "2\tHemsworth has also appeared in the science fiction action film Star Trek -LRB- 2009 -RRB- , the thriller adventure A Perfect Getaway -LRB- 2009 -RRB- , the horror comedy The Cabin in the Woods -LRB- 2012 -RRB- , the dark-fantasy action film Snow White and the Huntsman -LRB- 2012 -RRB- , the war film Red Dawn -LRB- 2012 -RRB- , and the biographical sports drama film Rush -LRB- 2013 -RRB- .\tStar Trek\tStar Trek (film)\tA Perfect Getaway\tA Perfect Getaway\tThe Cabin in the Woods\tThe Cabin in the Woods\tSnow White and the Huntsman\tSnow White and the Huntsman\tRed Dawn\tRed Dawn (2012 film)\tRush\tRush (2013 film)\n",
            "\n",
            "launched 2 processes\n",
            "Sentence after the cleaning:\n",
            "hemsworth also appeared science fiction action film star trek ( 2009 ) , thriller adventure a perfect getaway ( 2009 ) , horror comedy the cabin woods ( 2012 ) , dark-fantasy action film snow white huntsman ( 2012 ) , war film red dawn ( 2012 ) , biographical sports drama film rush ( 2013 ) . star trek star trek (film) a perfect getaway a perfect getaway the cabin woods the cabin woods snow white huntsman snow white huntsman red dawn red dawn ( 2012 film) rush rush ( 2013 film)\n"
          ]
        }
      ],
      "source": [
        "print('Sentence before the cleaning:')\n",
        "print(''.join(TRAIN_DF['Evidence'][0]))\n",
        "print('')\n",
        "\n",
        "def ser_prepr(ser, fun):\n",
        "    return ser.apply(fun)\n",
        "\n",
        "def per_column_parallel_apply(df, fun, cols, maxpr=4):\n",
        "    pool = mp.Pool(processes=min(df.shape[1], maxpr))\n",
        "    wait_g = [pool.apply_async(ser_prepr, args=(df[col], fun)) for col in df.columns[cols]]\n",
        "    print(f'launched {len(wait_g)} processes')\n",
        "    wait_g = iter(wait_g)\n",
        "    return pd.DataFrame({\n",
        "        df.columns[i]: (next(wait_g).get() if i in cols else df.iloc[:,i]) for i in range(df.shape[1])\n",
        "    })\n",
        "\n",
        "TRAIN_DF = per_column_parallel_apply(TRAIN_DF, preprocess_text, [1,2])\n",
        "\n",
        "print('Sentence after the cleaning:')\n",
        "print(TRAIN_DF['Evidence'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "24n0ihTbCU44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3ec318-b60e-44fc-bd68-bee5b878d7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "launched 2 processes\n"
          ]
        }
      ],
      "source": [
        "VALID_DF = per_column_parallel_apply(VALID_DF, preprocess_text, [1,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l3Lx_uNJlN7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378e2f85-d227-4976-c6b9-ede58628e0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "launched 2 processes\n"
          ]
        }
      ],
      "source": [
        "TEST_DF = per_column_parallel_apply(TEST_DF, preprocess_text, [1,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSdwDCRKCU45"
      },
      "source": [
        "## Fasttext embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kxK9RV_sCU46"
      },
      "outputs": [],
      "source": [
        "def update_corpus_file(dataframe):\n",
        "    global PATH\n",
        "    f = open(PATH + \"data.txt\", \"w\")\n",
        "    for i in range(len(dataframe)):\n",
        "        f.write(dataframe['Evidence'][i] + os.linesep)\n",
        "        f.write(dataframe['Claim'][i] + os.linesep )\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b6QjBGGpCU47"
      },
      "outputs": [],
      "source": [
        "fasttext.FastText.eprint = lambda x: None\n",
        "\n",
        "try:\n",
        "    MODEL = fasttext.load_model(PATH + \"embedding_model.bin\")\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "    update_corpus_file(TRAIN_DF)\n",
        "    MODEL = fasttext.train_unsupervised(PATH +'data.txt', model='skipgram', minCount=1, dim=200)\n",
        "    MODEL.save_model(PATH + \"embedding_model.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9sqoTELCU48"
      },
      "source": [
        "### Building embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "mtlFbHskCU48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cad2ee-3c39-494f-f915-f57e8e8bbe0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights matrix size: (40497, 200)\n",
            "Word_to_position_dictionary size: 40496\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIM = 200\n",
        "WORD_TO_POSITION_DICTIONARY = {}\n",
        "\n",
        "for i,word in enumerate(MODEL.words):\n",
        "    WORD_TO_POSITION_DICTIONARY[word] = i+1\n",
        "    \n",
        "WEIGHT_MATRIX=np.array([0 for i in range(EMBEDDING_DIM)]).reshape(1,-1)    \n",
        "WEIGHT_MATRIX = np.concatenate((WEIGHT_MATRIX,np.array([MODEL.get_word_vector(i) for i in WORD_TO_POSITION_DICTIONARY])))\n",
        "\n",
        "print(f'Weights matrix size: {WEIGHT_MATRIX.shape}')\n",
        "print(f'Word_to_position_dictionary size: {len(WORD_TO_POSITION_DICTIONARY)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "kSeJYLt7CU49"
      },
      "outputs": [],
      "source": [
        "WORD_TO_POSITION_DD = autoIntDict(dict(WORD_TO_POSITION_DICTIONARY))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u31m-PEDCU5A"
      },
      "source": [
        "## Data conversion and data iterators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "lFxZ2CvyCU5B"
      },
      "outputs": [],
      "source": [
        "def update_embed_matrix(df, new_words):\n",
        "    ''' Updates WEIGHT_MATRIX inplace by adding it the vectors predicted \n",
        "    by the FastText model (appending them to the 1st dimension.) '''\n",
        "    global WEIGHT_MATRIX, MODEL\n",
        "\n",
        "    for word in new_words:\n",
        "        new_embedding = MODEL.get_word_vector(word)\n",
        "        WEIGHT_MATRIX = np.concatenate((WEIGHT_MATRIX, new_embedding.reshape((1,len(WEIGHT_MATRIX[0])))))\n",
        "        \n",
        "    print(f'Weights matrix size: {WEIGHT_MATRIX.shape}')\n",
        "        \n",
        "\n",
        "def apply_conversion(df, word_to_pos_dd):\n",
        "    '''Encodes a dataframe by applying an incremental encoding to the 1st column (specified\n",
        "    by one_hot_dictionary) and a one-hot encoding to the 2nd: '''\n",
        "    global WEIGHT_MATRIX\n",
        "  \n",
        "    max_pad_len = df.iloc[:,2].apply(len).max()\n",
        "                \n",
        "    col1 = df['Evidence'].apply(lambda _: [word_to_pos_dd[l]  for l in word_tokenize(_) ])\n",
        "    col2 = df['Claim'].apply(lambda _: [word_to_pos_dd[l]  for l in word_tokenize(_) ])\n",
        "    dic = { 'SUPPORTS':tensor([0,1]), 'REFUTES':tensor([1,0]) }\n",
        "    col3 = df['Label'].apply(lambda x:dic[x])\n",
        "        \n",
        "    encoded_df = pd.DataFrame(zip(col1,col2,col3,df['ID']), columns=['Evidence','Claim','Label','ID'])\n",
        "        \n",
        "    update_embed_matrix(df, word_to_pos_dd.get_newly_added())\n",
        "          \n",
        "    return encoded_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU7Cvqo_CU5D"
      },
      "source": [
        "### Data conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "xAogcNXpCU5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ab399621-a755-4f52-9a7f-e403ecb55648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights matrix size: (40718, 200)\n",
            "Weights matrix size: (42434, 200)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-62284c4f-4394-435b-8753-873110e1051e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Evidence</th>\n",
              "      <th>Claim</th>\n",
              "      <th>Label</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1897, 45, 151, 60, 52, 92, 7, 108, 727, 4, 14...</td>\n",
              "      <td>[251, 1897, 151, 32, 723, 4764, 2]</td>\n",
              "      <td>[tensor(0), tensor(1)]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5018, 4475, 4, 1, 33, 370, 146, 6436, 28, 431...</td>\n",
              "      <td>[5018, 4475, 200, 2]</td>\n",
              "      <td>[tensor(0), tensor(1)]</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[5018, 4475, 4, 1, 33, 370, 146, 6436, 28, 431...</td>\n",
              "      <td>[5018, 4475, 606, 2]</td>\n",
              "      <td>[tensor(1), tensor(0)]</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[5, 172, 17, 2881, 5784, 7064, 19254, 1795, 61...</td>\n",
              "      <td>[476, 7064, 19254, 1795, 2]</td>\n",
              "      <td>[tensor(0), tensor(1)]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[5, 172, 17, 2881, 5784, 7064, 19254, 1795, 61...</td>\n",
              "      <td>[476, 7064, 19254, 1795, 2]</td>\n",
              "      <td>[tensor(1), tensor(0)]</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62284c4f-4394-435b-8753-873110e1051e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62284c4f-4394-435b-8753-873110e1051e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62284c4f-4394-435b-8753-873110e1051e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Evidence  ...  ID\n",
              "0  [1897, 45, 151, 60, 52, 92, 7, 108, 727, 4, 14...  ...   3\n",
              "1  [5018, 4475, 4, 1, 33, 370, 146, 6436, 28, 431...  ...   7\n",
              "2  [5018, 4475, 4, 1, 33, 370, 146, 6436, 28, 431...  ...   8\n",
              "3  [5, 172, 17, 2881, 5784, 7064, 19254, 1795, 61...  ...   9\n",
              "4  [5, 172, 17, 2881, 5784, 7064, 19254, 1795, 61...  ...  10\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "ENCODED_TRAIN_DF = apply_conversion(TRAIN_DF, WORD_TO_POSITION_DD) \n",
        "ENCODED_VALID_DF = apply_conversion(VALID_DF, WORD_TO_POSITION_DD)\n",
        "\n",
        "ENCODED_TRAIN_DF.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukbd8MAXCU5F"
      },
      "source": [
        "### Data iterators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bg47nzomCU5F"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "EVID_PAD_LENGTH=0\n",
        "CLAIM_PAD_LENGTH=0\n",
        "datasets = [CustomTextDataset(_) for _ in (ENCODED_TRAIN_DF, ENCODED_VALID_DF)]  \n",
        "\n",
        "train_dataset, val_dataset = datasets  \n",
        "\n",
        "def Define_padding(type=\"local\",method=np.max):\n",
        "    \"\"\"return the collate fn based on the parameter if local the function simply pad the batch to the max lenght in the batch else it uses method to calculate the padding lenght \"\"\"\n",
        "    global ENCODED_TRAIN_DF, EVID_PAD_LENGTH, CLAIM_PAD_LENGTH\n",
        "    EVID_PAD_LENGTH=method(ENCODED_TRAIN_DF['Evidence'].apply(lambda x:len(x)))\n",
        "    CLAIM_PAD_LENGTH=method(ENCODED_TRAIN_DF['Claim'].apply(lambda x:len(x)))\n",
        "\n",
        "    def padding(list_tensors,lenght,batch_first=True, padding_value=0):\n",
        "        \"\"\"returns a tensor which is the concatenation of all the tensors in the list (all padded to the same lenght) \"\"\"\n",
        "        sizes= [i.size()[-1] for i in list_tensors]\n",
        "        to_cat=[pad(list_tensors[i],(0,lenght-sizes[i]),value = padding_value) for i in range(len(sizes))]\n",
        "        return torch.stack(to_cat,dim=0)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        global DEVICE\n",
        "        labels = torch.from_numpy(np.array([i[2].numpy() for i in batch],dtype=int))\n",
        "        texts = [torch.from_numpy(np.array(i[1], dtype=int)) for i in batch]\n",
        "        evidences = [torch.from_numpy(np.array(i[0],dtype=int))  for i in batch]\n",
        "        #Applying padding\n",
        "        if(type==\"local\"):\n",
        "            texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
        "            evidences = pad_sequence(evidences, batch_first=True, padding_value=0)\n",
        "        elif(type == \"global\"):\n",
        "            texts=padding(texts,CLAIM_PAD_LENGTH)\n",
        "            evidences = padding(evidences,EVID_PAD_LENGTH)\n",
        "        return (labels.to(DEVICE), evidences.to(DEVICE), texts.to(DEVICE))\n",
        "    \n",
        "    return collate_fn \n",
        "  \n",
        "\n",
        "train_dataloader, val_dataloader = \\\n",
        "  (DataLoader(_, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Define_padding()) for _ in datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Eh5-MK_CU5H"
      },
      "source": [
        "## Functions for the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT2gHQFgCU5H"
      },
      "source": [
        "### Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TUL4fBH0CU5I"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, optimizer, epoch=None, criterion=torch.nn.CrossEntropyLoss(), verbose=True, log_interval=300):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    start_time = time.time()\n",
        "    losses = []\n",
        "    \n",
        "    for idx, (label, evidence, text) in enumerate(dataloader):\n",
        "        optimizer.zero_grad() \n",
        "        predicted_label = model(text, evidence)  \n",
        "        loss = criterion(predicted_label, label.argmax(1))\n",
        "        loss.backward()                                          \n",
        "        losses.append(loss.item())       \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        model.embedding.weight.grad[tensor(0)] = 0 \n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1)==label.argmax(1)).sum().item()\n",
        "        total_count += label.size()[0]                         \n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            if verbose:\n",
        "                print(f'| epoch {(epoch if epoch else 0):3d} | {idx:5d}/{len(dataloader):5d} batches |' \n",
        "                      + f' accuracy { total_acc/total_count:8.3f}| loss {losses[-1]:.5f}')\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "            \n",
        "    return losses, total_acc/total_count\n",
        "\n",
        "def evaluate(dataloader, model, criterion=torch.nn.CrossEntropyLoss(), retain=False):\n",
        "    ''' Evaluates 'model' over the dataloader.\n",
        "      Returns the history of the loss values and the tag-level accuracy.\n",
        "    '''\n",
        "    model.eval()\n",
        "    accumulated_good_pred, total_count = 0, 0\n",
        "    val_steps = 0.0, 0\n",
        "    accumulated_loss, history = [], []\n",
        "    with torch.no_grad():\n",
        "        for idx, (label,evidence, text) in enumerate(dataloader):\n",
        "            predicted_label = model(text, evidence) \n",
        "            loss = criterion(predicted_label, label.argmax(1)) \n",
        "            accumulated_good_pred += (predicted_label.argmax(1)==label.argmax(1)).sum().item()\n",
        "            total_count += label.size()[0]\n",
        "            accumulated_loss.append(loss.item())\n",
        "            if retain:\n",
        "                y_true = label.argmax(1).cpu().numpy()\n",
        "                y_pred = predicted_label.argmax(1).cpu().numpy()\n",
        "                history += zip(y_true, y_pred)\n",
        "    return accumulated_loss, accumulated_good_pred/total_count, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJzrv5w1CU5J"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y2YjV6eL9N7E"
      },
      "outputs": [],
      "source": [
        "def get_f1_score(hist):\n",
        "    y_true, y_pred = zip(*hist)\n",
        "    return f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "def get_recall_score(hist):\n",
        "    y_true, y_pred = zip(*hist)\n",
        "    return recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "def get_precision(hist):\n",
        "    y_true, y_pred = zip(*hist)\n",
        "    return precision_score(y_true, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2iH5MGjTCU5K"
      },
      "outputs": [],
      "source": [
        "def train_loop(\n",
        "    create_model,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    params = {'hidden': 256, 'LR_Adam': 0.0001},\n",
        "    criterion = torch.nn.CrossEntropyLoss(),\n",
        "    scheduler_ = torch.optim.lr_scheduler.StepLR,\n",
        "    create_optimizer = 'default',\n",
        "    scheduler_parr = {'step_size': 8, 'gamma':.1},\n",
        "    epochs = 20,\n",
        "    early_stop_patience = 4,\n",
        "    verbose = False,\n",
        "    log_interval=300,\n",
        "    return_last_checkpoint = False\n",
        "):\n",
        "    global train, evaluate,DEVICE\n",
        "    highlight = lambda _:f'{\"-\"*(len(_)+4)}\\n  {_}\\n{\"-\"*(len(_)+4)}'\n",
        "    try:\n",
        "        model = create_model(hidden=params['hidden']).to(DEVICE)\n",
        "        if create_optimizer=='default':\n",
        "            create_optimizer = lambda model_pars: torch.optim.Adam(model_pars, lr=params['LR_Adam'])\n",
        "        optimizer = create_optimizer(model.parameters())\n",
        "        scheduler = scheduler_(optimizer = optimizer, **scheduler_parr)\n",
        "        total_accu = None\n",
        "        last_loss = 100\n",
        "        trigger_times = 0\n",
        "        metrics = {'train_loss': [],\n",
        "                  'val_loss': [],\n",
        "                  'train_loss_hist': [],\n",
        "                  'train_acc': [],\n",
        "                  'val_acc': [],\n",
        "                  'f1_score': 0,\n",
        "                   'recall':0}\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            epoch_start_time = time.time()\n",
        "            losses_train, accu_train = train(train_dataloader, model, optimizer,\n",
        "              verbose=verbose, criterion=criterion, epoch=epoch,\n",
        "              log_interval=log_interval)\n",
        "            loss_vals, accu_val, hist = evaluate(val_dataloader, model, criterion=criterion, retain=True)\n",
        "            current_val_loss = np.mean(loss_vals)\n",
        "\n",
        "            metrics['train_loss'].append(np.mean(losses_train))\n",
        "            metrics['val_loss'].append(current_val_loss)\n",
        "            metrics['train_loss_hist'].append(losses_train)\n",
        "            metrics['train_acc'].append(accu_train)\n",
        "            metrics['val_acc'].append(accu_val)\n",
        "            \n",
        "\n",
        "            if total_accu is not None and total_accu > accu_val:\n",
        "                scheduler.step()\n",
        "            else: total_accu = accu_val\n",
        "            if verbose:\n",
        "                print(highlight(f'| end of epoch {epoch:3d} | time: {time.time() - epoch_start_time:5.2f}s | '\n",
        "                f'valid accuracy {accu_val:8.3f} | valid loss:{current_val_loss:8.3f}'))\n",
        "            else:\n",
        "                print(end=f\"\\rDoing epoch: {epoch:2}\", flush=True)\n",
        "          \n",
        "            #Early stopping\n",
        "            if current_val_loss > last_loss:\n",
        "                trigger_times += 1\n",
        "                if trigger_times >= early_stop_patience:\n",
        "                    print(\"\\n === Early Stopping ===\\n\")\n",
        "                    metrics['f1_score'] = get_f1_score(hist)\n",
        "                    metrics['recall'] = get_recall_score(hist)\n",
        "                    print(\"\\rVal_accuracy: \", accu_val, ' - F1-score: ', metrics['f1_score'],' - Recall:', metrics['recall'])\n",
        "                    break\n",
        "            else:  trigger_times = 0\n",
        "            last_loss = current_val_loss\n",
        "\n",
        "        if epoch==epochs:\n",
        "            metrics['f1_score'] = get_f1_score(hist)\n",
        "            metrics['recall'] = get_recall_score(hist)\n",
        "            print(\"\\rVal_accuracy: \", accu_val, ' - F1-score: ', metrics['f1_score'],' - Recall:', metrics['recall'])\n",
        "        print()\n",
        "        \n",
        "    except Exception: raise\n",
        "    else: return model, metrics\n",
        "    finally:\n",
        "        if return_last_checkpoint:\n",
        "            cp = {\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()}\n",
        "            return model, metrics, cp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxCSrQaxCU5M"
      },
      "source": [
        "### Print plots function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l1rcrRAACU5M"
      },
      "outputs": [],
      "source": [
        "def print_plots(metrics, complete_loss=False, size=(20,7)):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(*size)\n",
        "\n",
        "    ax1.plot(metrics['train_loss'], '.-')\n",
        "    ax1.plot(metrics['val_loss'], '.-')\n",
        "    ax1.grid(True)\n",
        "    if complete_loss:\n",
        "        ax1.plot(metrics['train_loss_hist'], '.')\n",
        "        ax1.set_ylim(0, np.max(metrics['train_loss_hist'])*1.1)\n",
        "    else:\n",
        "        ax1.set_ylim(0, np.max(metrics['val_loss']+metrics['train_loss'])*1.1)\n",
        "    ax1.set_title('model loss')\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.set_xlabel('epochs')\n",
        "    ax1.set_xticks(range(len(metrics['train_loss'])))\n",
        "    leg_lab = ['train_loss', 'val_loss']\n",
        "    ax1.legend(leg_lab + ['train_complete_loss'] if complete_loss else leg_lab,\n",
        "               loc='upper right')\n",
        "    m1, m2 = np.max(metrics['train_acc']), np.max(metrics['val_acc'])\n",
        "    ax2.axhline(y=m1, color='gray', linestyle='-.')\n",
        "    ax2.axhline(y=m2, color='gray', linestyle='-.')\n",
        "    ax2.plot(metrics['train_acc'], '.-')\n",
        "    ax2.plot(metrics['val_acc'], '.-')\n",
        "    ax2.set_title('model accuracy')\n",
        "    ax2.set_ylabel('accuracy')\n",
        "    ax2.set_xlabel('epochs')\n",
        "    ax2.set_xticks(range(len(metrics['train_loss'])))\n",
        "    ticks_ = list(ax2.get_yticks())+[m1,m2]\n",
        "    ax2.set_yticks(ticks=ticks_)\n",
        "    ax2.set_yticklabels([f'{_:.2}' for _ in ticks_])\n",
        "    ax2.grid(True)\n",
        "    ax2.legend(['train_acc', 'val_acc'], loc='lower right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU0xP5qgCU5N"
      },
      "source": [
        "### Tuning function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6ibhv00CCU5O"
      },
      "outputs": [],
      "source": [
        "def tune(\n",
        "    create_model,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    param_dict,\n",
        "    criterion=torch.nn.CrossEntropyLoss(),\n",
        "    scheduler_ = torch.optim.lr_scheduler.StepLR,\n",
        "    scheduler_parr = {'step_size':8, 'gamma':.1},\n",
        "    epochs = 12,\n",
        "    early_stop_patience = 4,\n",
        "    verbose = False\n",
        "):\n",
        "    global train, evaluate, DEVICE\n",
        "    results = pd.DataFrame(columns=list(param_dict.keys()) + [\"val_accuracy\"] + [\"F1_score\"])\n",
        "    \n",
        "    for opt in param_dict['optimizer']:\n",
        "        for LR in param_dict['learning_rate'][opt]:\n",
        "            for hidden in param_dict['hidden_size']:\n",
        "                model = create_model(hidden=hidden).to(DEVICE)\n",
        "                optimizer = torch.optim.Adam(model.parameters(), lr=LR) if opt==\"Adam\" else torch.optim.SGD(model.parameters(), lr=LR)\n",
        "                scheduler = scheduler_(optimizer = optimizer, **scheduler_parr)\n",
        "                \n",
        "                total_accu = None\n",
        "                last_loss = 100\n",
        "                trigger_times = 0\n",
        "                print(f\"Optimizer: {opt} | LR = {LR} | Hidden_size = {hidden}\")\n",
        "                for epoch in range(1, epochs + 1):\n",
        "                    epoch_start_time = time.time()\n",
        "                    train(train_dataloader, model, optimizer, verbose=verbose, criterion=criterion)\n",
        "                    loss_vals, accu_val, hist= evaluate(val_dataloader, model, criterion=criterion, retain=True)\n",
        "                    current_val_loss = np.mean(loss_vals)\n",
        "                    if total_accu is not None and total_accu > accu_val:\n",
        "                        scheduler.step()\n",
        "                    else: total_accu = accu_val\n",
        "                    print(end=f\"\\rDoing epoch: {epoch:2}\", flush=True)\n",
        "                    if epoch==epochs:\n",
        "                        final_f1_score=get_f1_score(hist)\n",
        "                        print(f\"\\rVal_accuracy: {accu_val}, F1-score: {final_f1_score}\")\n",
        "                        results = results.append({\"optimizer\": opt, \"learning_rate\": LR, \"hidden_size\": hidden, \"val_accuracy\": accu_val,\\\n",
        "                                                }, ignore_index=True)\n",
        "                    #Early stopping\n",
        "                    if current_val_loss > last_loss:\n",
        "                        trigger_times += 1\n",
        "                        if trigger_times >= early_stop_patience:\n",
        "                            results = results.append({\"optimizer\": opt, \"learning_rate\": LR, \"hidden_size\": hidden, \"val_accuracy\": accu_val,\\\n",
        "                                                }, ignore_index=True)\n",
        "\n",
        "                            print(\" === Early Stopping === \")\n",
        "                            break\n",
        "                    else:  trigger_times = 0\n",
        "                    last_loss = current_val_loss\n",
        "            print()\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es08nthdCU5P"
      },
      "source": [
        "## Models and Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQO1yklwYUBG"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0wHUONlaCU5Q"
      },
      "outputs": [],
      "source": [
        "def get_fc_layer_Relu(name,\n",
        "                    features_in,\n",
        "                    features_out):\n",
        "    \"\"\"Gets a sequential container with a sandwich of Fully connected layer \n",
        "       and Softmax.\n",
        "    Args:\n",
        "        name: the name prefix to append to each layer in the container.\n",
        "        features_in: the number of the input features.\n",
        "        features_out: the number of the output features.\n",
        "\n",
        "    Returns: the created sequential.\n",
        "    \"\"\"\n",
        "    container = nn.Sequential()\n",
        "    container.add_module(f'{name}_fc', nn.Linear(in_features=features_in, out_features=features_out))    \n",
        "    container.add_module(f'{name}_Relu', nn.ReLU())\n",
        "    return container\n",
        "\n",
        "def get_fc_Dropout(name,\n",
        "                    features_in,\n",
        "                    features_out):\n",
        "    \"\"\"Gets a sequential container with a sandwich of Fully connected layers \n",
        "       with Dropout.\n",
        "    Args:\n",
        "        name: the name prefix to append to each layer in the container.\n",
        "        features_in: the number of the input features.\n",
        "        features_out: the number of the output features.\n",
        "\n",
        "    Returns: the created sequential.\n",
        "    \"\"\"\n",
        "    container = nn.Sequential()\n",
        "    container.add_module(f'{name}_fc_Relu_1', get_fc_layer_Relu(\"fc_1\", features_in, features_out))    \n",
        "    container.add_module(f'{name}_Dropout', nn.Dropout(0.5))\n",
        "    return container"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yLW09x4YUBH"
      },
      "source": [
        "### Definition of the architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm4XEtPKCU5R"
      },
      "source": [
        "Different way in which the sentence embedding will be done:\n",
        "+ LRNN : last layer of RNN\n",
        "+ MRNN : mean of RNN layers\n",
        "+ MLP  : multi layer Perceptron\n",
        "+ ME   : Mean of Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RK7-O7shCU5R"
      },
      "outputs": [],
      "source": [
        "# Difference for the merging of the embedding of evidence and claim\n",
        "class Merg_Mode(Enum):  \n",
        "    CONCAT = torch.cat\n",
        "    SUM    = torch.sum\n",
        "    MEAN   = torch.mean\n",
        "    def as_f(self, *coup):\n",
        "        return self.value(coup if self.value is torch.cat else torch.stack(coup, dim=1), dim=1)\n",
        "\n",
        "\n",
        "class Base_RCNN (nn.Module):\n",
        "    \"\"\" Class Modelling the RCNN taking the last layer of the RNN as the sentence emebedding embedding\"\"\"\n",
        "    def update_embedding(self, w_mat):\n",
        "        assert(len(w_mat.shape)>1)\n",
        "        self.embedding = nn.Embedding(*w_mat.shape)\n",
        "        self.embedding.weight = nn.Parameter(torch.from_numpy(w_mat))\n",
        "        \n",
        "    def __init__(self, n_output,\n",
        "                 merging_mode = Merg_Mode.CONCAT,\n",
        "                 hidden = 32,\n",
        "                 class_weights = None,\n",
        "                 cs=False,\n",
        "                 **_):\n",
        "        super(Base_RCNN, self).__init__()\n",
        "        self.merging = merging_mode\n",
        "        self.hidden_size = hidden\n",
        "        self.update_embedding(WEIGHT_MATRIX) \n",
        "        self.sentence_embed_arch = None\n",
        "        self.result = None\n",
        "        self.embedding(tensor(0))\n",
        "        self.feature_size = hidden * (2 if merging_mode is Merg_Mode.CONCAT else 1)\n",
        "        self.fc = get_fc_Dropout(\"fc_dropout\", self.feature_size, self.feature_size)\n",
        "        self.cs= nn.CosineSimilarity() if cs else cs\n",
        "        self.final_fc = nn.Linear(cs + self.feature_size*2, n_output)\n",
        "        \n",
        "    @contextlib.contextmanager\n",
        "    def forward(self, x_, y_):\n",
        "        x = self.embedding(x_)\n",
        "        y = self.embedding(y_)\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ePPGd53GCU5T"
      },
      "outputs": [],
      "source": [
        "class LRNN(Base_RCNN):\n",
        "    def __init__(self, n_output, **dp):\n",
        "        super(LRNN, self).__init__(n_output, **dp)\n",
        "        self.sentence_embed_arch = nn.GRU(\n",
        "            batch_first = True,\n",
        "            input_size = WEIGHT_MATRIX.shape[1],\n",
        "            hidden_size = self.hidden_size,\n",
        "            bidirectional = True\n",
        "        )\n",
        "\n",
        "    def forward(self, x_, y_):\n",
        "        with super(LRNN, self).forward(x_, y_) as (x,y):\n",
        "            _, y = self.sentence_embed_arch(y.to(torch.float32))\n",
        "            _, x = self.sentence_embed_arch(x.to(torch.float32))\n",
        "            x = x[1,:,:].squeeze()\n",
        "            y = y[1,:,:].squeeze()\n",
        "            merged = self.merging.as_f(x,y).to(torch.float32)\n",
        "            output = self.fc(merged)\n",
        "            to_cat=[output,merged] +([] if not self.cs else [self.cs(x,y).unsqueeze(dim=1)])\n",
        "            \n",
        "            self.result = self.final_fc(torch.cat(to_cat,dim=-1))\n",
        "        return self.result\n",
        "\n",
        "\n",
        "class MRNN(Base_RCNN):\n",
        "    def __init__(self, n_output, **dp):\n",
        "        super(MRNN, self).__init__(n_output, **dp)\n",
        "        self.sentence_embed_arch = nn.GRU(\n",
        "            batch_first = True,\n",
        "            input_size = WEIGHT_MATRIX.shape[1],\n",
        "            hidden_size = self.hidden_size,\n",
        "            bidirectional = True\n",
        "        )\n",
        "    def forward(self, x_, y_):\n",
        "        with super(MRNN, self).forward(x_, y_) as (x,y):\n",
        "            y , _ = self.sentence_embed_arch(y.to(torch.float32))\n",
        "            x , _ = self.sentence_embed_arch(x.to(torch.float32))\n",
        "            x = torch.mean(x[:,:,self.hidden_size:], dim=1)\n",
        "            y = torch.mean(y[:,:,self.hidden_size:], dim=1)\n",
        "            merged = self.merging.as_f(x,y)\n",
        "            output = self.fc(merged)\n",
        "            to_cat=[output,merged] +([] if not self.cs else [self.cs(x,y).unsqueeze(dim=1)])\n",
        "            self.result = self.final_fc(torch.cat(to_cat,dim=-1))\n",
        "        return self.result\n",
        "\n",
        "\n",
        "class MLP(Base_RCNN):\n",
        "    def __init__(self, n_output, **dp):\n",
        "        global EVID_PAD_LENGTH, CLAIM_PAD_LENGTH\n",
        "        super(MLP, self).__init__(n_output, **dp)\n",
        "        #Encoding\n",
        "        self.evid_embed_arch = get_fc_layer_Relu('MLP_Evidence_encoder', \n",
        "                                                 WEIGHT_MATRIX.shape[1]*EVID_PAD_LENGTH, \n",
        "                                                 self.hidden_size) \n",
        "        self.claim_embed_arch = get_fc_layer_Relu('MLP_Claim_encoder', \n",
        "                                                  WEIGHT_MATRIX.shape[1]*CLAIM_PAD_LENGTH, \n",
        "                                                  self.hidden_size) \n",
        "    def forward(self, x_, y_):\n",
        "        with super(MLP, self).forward(x_, y_) as (x,y):\n",
        "            x = self.claim_embed_arch(x.reshape((x.size(0),-1)).to(torch.float32))\n",
        "            y = self.evid_embed_arch (y.reshape((y.size(0),-1)).to(torch.float32))\n",
        "            merged = self.merging.as_f(x,y).to(torch.float32)\n",
        "            output = self.fc(merged)\n",
        "            to_cat=[output,merged] +([] if not self.cs else [self.cs(x,y).unsqueeze(dim=1)])\n",
        "            self.result = self.final_fc(torch.cat(to_cat,dim=-1))\n",
        "        return self.result\n",
        "\n",
        "\n",
        "class ME(Base_RCNN):\n",
        "    def __init__(self, n_output, **dp):\n",
        "        \n",
        "        super(ME, self).__init__(n_output, **dp)\n",
        "        self.cs= nn.CosineSimilarity() if dp['cs'] else dp['cs']\n",
        "        self.feature_size = (WEIGHT_MATRIX.shape[1])*(1+(self.merging is Merg_Mode.CONCAT))\n",
        "        self.fc = get_fc_Dropout(\"fc_dropout\", self.feature_size, self.feature_size)\n",
        "        self.final_fc=nn.Linear( dp['cs'] + self.feature_size*2, n_output)\n",
        "    def forward(self, x_, y_):\n",
        "        with super(ME, self).forward(x_, y_) as (x,y):\n",
        "            x = torch.mean(x.to(torch.float32), dim=1)\n",
        "            y = torch.mean(y.to(torch.float32), dim=1)\n",
        "            merged = self.merging.as_f(x,y).to(torch.float32)\n",
        "            output = self.fc(merged)\n",
        "            to_cat=[output,merged] +([] if not self.cs else [self.cs(x,y).unsqueeze(dim=1)])\n",
        "            self.result = self.final_fc(torch.cat(to_cat,dim=-1))\n",
        "        return self.result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGtJno4tlN73"
      },
      "source": [
        "## Dealing with the imbalance of the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPkbKxFflN73"
      },
      "source": [
        "We tried two different approaches for dealing with the imbalance of the dataset.\n",
        "* Applying class weights to the loss function\n",
        "* Applying a sampling of the dataset and feeding the network in balanced way \n",
        "\n",
        "With these two approaches we got comparable results so we decided to keep the use of weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nea_O3g1CU5U"
      },
      "source": [
        "### Computation of the class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "d2NKGpm6CU5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b24b92-7725-4523-c05a-941b61ea62fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.526197, 2.723825], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "def weigth_calc(encoded_train_df):\n",
        "    one_hot_matrix=np.array([i.numpy()for i in encoded_train_df['Label']])\n",
        "    weight_by_class=np.sum(one_hot_matrix)/np.sum(one_hot_matrix,axis=0)*2\n",
        "    return weight_by_class\n",
        "  \n",
        "WEIGHTS = weigth_calc(ENCODED_TRAIN_DF).astype(np.float32)\n",
        "WEIGHTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89tcbQGOlN73"
      },
      "source": [
        "### Sampling of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nytOl3jElN74"
      },
      "outputs": [],
      "source": [
        "ctd = CustomTextDataset(ENCODED_TRAIN_DF)\n",
        "\n",
        "W_TRAIN_DATALOADER = DataLoader(\n",
        "    ctd,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=Define_padding(),\n",
        "    sampler = torch.utils.data.sampler.WeightedRandomSampler(\n",
        "      weights=[(WEIGHTS[0] if ctd[_][2].item==0 else WEIGHTS[1]) for _ in range(len(ctd))], \n",
        "      num_samples = 952 * BATCH_SIZE,\n",
        "      replacement=True)\n",
        "    )\n",
        "\n",
        "W_VAL_DATALOADER = DataLoader(\n",
        "    CustomTextDataset(ENCODED_VALID_DF),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=Define_padding(),\n",
        "    sampler=torch.utils.data.sampler.WeightedRandomSampler(\n",
        "      weights=[(WEIGHTS[0] if ctd[_][2].item==0 else WEIGHTS[1]) for _ in range(len(ctd))], \n",
        "      num_samples = 952 * BATCH_SIZE,\n",
        "      replacement=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPKKfeI0CU5V"
      },
      "source": [
        "## Training models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhRuACZtehrd"
      },
      "source": [
        "### Stupid baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWkoZluyelGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e9fce0-7b99-4cf9-bcdf-daa14fa5cfdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('BASELINE ACCURACY: 0.734', 'BASELINE ACCURACY ON VALID.: 0.504')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "class dummy(nn.Module):\n",
        "      def forward(self, x_, y_, *a, **aa):\n",
        "            t = tensor([0.,1.], device=DEVICE).repeat(len(x_),1)\n",
        "            return t\n",
        "\n",
        "f'BASELINE ACCURACY: {evaluate(train_dataloader, dummy())[1]:.3f}',\\\n",
        "f'BASELINE ACCURACY ON VALID.: {evaluate(val_dataloader, dummy())[1]:.3f}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgpcyP47YUBS"
      },
      "source": [
        "### LRNN architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWq_d79_YUBT"
      },
      "source": [
        "#### Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2tE0GB3lN74"
      },
      "source": [
        "We applied the fine-tuning of the hyperparameters for all the combination of the model architectures. For brevity we put in the notebook only the code an explanatory example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-qBxBjBYUBU"
      },
      "outputs": [],
      "source": [
        "'''results = tune(\n",
        "    lambda **pp:  LRNN(n_output=2, **pp).to(DEVICE),\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    { \"optimizer\": [\"Adam\",\"SGD\"],\n",
        "      \"learning_rate\": { \"Adam\": [0.01, 0.001, 0.0001], \"SGD\": [0.1, 0.01]},\n",
        "      \"hidden_size\": [128, 256]},\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "best_configuration = results[results[\"F1_score\"] == max(results[\"F1_score\"])]\n",
        "best_configuration\n",
        "''';"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MMq_5nIYUBU"
      },
      "source": [
        "Best configuration: Adam | LR = 0.0001 | Hidden = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiB-d64bYUBV"
      },
      "source": [
        "#### Trainings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYakRTxolN75"
      },
      "source": [
        "Training without Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yuj2aAbyYUBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524c662f-4d4c-4342-b6a9-15990ed757ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.733| loss 0.69358\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.403| loss 0.67754\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.596| loss 0.64139\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 62.78s | valid accuracy    0.603 | valid loss:   0.761\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.732| loss 0.67261\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.599| loss 0.60224\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.694| loss 0.56280\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 62.41s | valid accuracy    0.633 | valid loss:   0.747\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.756| loss 0.66590\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.645| loss 0.56420\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.726| loss 0.53840\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 62.05s | valid accuracy    0.647 | valid loss:   0.726\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.772| loss 0.65123\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.672| loss 0.53284\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.747| loss 0.50168\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 62.13s | valid accuracy    0.655 | valid loss:   0.717\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.784| loss 0.64445\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.694| loss 0.51517\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.761| loss 0.47870\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 61.63s | valid accuracy    0.664 | valid loss:   0.710\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.793| loss 0.61451\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.711| loss 0.50354\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.773| loss 0.46804\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 62.08s | valid accuracy    0.668 | valid loss:   0.722\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.801| loss 0.58849\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.727| loss 0.48310\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.784| loss 0.45763\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 62.19s | valid accuracy    0.670 | valid loss:   0.731\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.808| loss 0.53982\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.739| loss 0.46558\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.794| loss 0.43697\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 61.97s | valid accuracy    0.671 | valid loss:   0.785\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.813| loss 0.51275\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.751| loss 0.44675\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.803| loss 0.42300\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 62.12s | valid accuracy    0.673 | valid loss:   0.838\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6727145847871598  - F1-score:  0.6630082784766647  - Recall: 0.6714069449831823\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_LRNN_Concat, metrics_LRNN_Concat = train_loop(\n",
        "           lambda **pp:  LRNN(n_output=2, merging_mode = Merg_Mode.CONCAT, cs=False, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20, \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001},\n",
        "           scheduler_parr = {'step_size': 8, 'gamma':.1},\n",
        "           early_stop_patience = 4 ,\n",
        "           verbose=True\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR7qq-uWlN75"
      },
      "source": [
        "Training with Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BvUnwDUXOda8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3595f627-38a1-4deb-fad0-7254b635b463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.731| loss 0.68393\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.412| loss 0.67688\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.602| loss 0.61704\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 66.24s | valid accuracy    0.607 | valid loss:   0.753\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.727| loss 0.67562\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.599| loss 0.60595\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.695| loss 0.55388\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 62.87s | valid accuracy    0.637 | valid loss:   0.741\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.756| loss 0.65563\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.647| loss 0.56948\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.728| loss 0.50988\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 62.93s | valid accuracy    0.652 | valid loss:   0.724\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.772| loss 0.63692\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.674| loss 0.53877\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.747| loss 0.47637\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 62.99s | valid accuracy    0.658 | valid loss:   0.715\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.783| loss 0.60558\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.695| loss 0.51916\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.763| loss 0.46650\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 63.08s | valid accuracy    0.665 | valid loss:   0.727\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.793| loss 0.59538\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.714| loss 0.50295\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.775| loss 0.45908\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 63.09s | valid accuracy    0.669 | valid loss:   0.742\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.800| loss 0.55394\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.727| loss 0.49125\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.787| loss 0.45918\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 63.33s | valid accuracy    0.672 | valid loss:   0.771\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.807| loss 0.53310\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.739| loss 0.47435\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.797| loss 0.46420\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 62.76s | valid accuracy    0.673 | valid loss:   0.817\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6725750174459176  - F1-score:  0.6631419507289273  - Recall: 0.6712862451955797\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_LRNN_Concat_cs, metrics_LRNN_Concat_cs = train_loop(\n",
        "           lambda **pp:  LRNN(n_output=2, merging_mode = Merg_Mode.CONCAT, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20, \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001},\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 4 ,\n",
        "           verbose=True\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu5qyp8ulN75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306353d8-1e90-4bf1-e1b5-b1c62d6af895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LRNN without cosine similarity | Validation F1-score macro: 0.6630082784766647\n",
            "Model: LRNN with cosine similarity    | Validation F1-score macro: 0.6633057679611347\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model: LRNN without cosine similarity | Validation F1-score macro: {metrics_LRNN_Concat['f1_score']}\")\n",
        "print(f\"Model: LRNN with cosine similarity    | Validation F1-score macro: {metrics_LRNN_Concat_cs['f1_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WbHRfD5lN76"
      },
      "source": [
        "We notice that with the cosine similarity extention we obtain slightly better results. So from here on we proceed using this extention in our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwJpaR1sOp8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284fb983-5c30-4dc9-9f23-e7137dc711ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.720| loss 0.67527\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.407| loss 0.69025\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.559| loss 0.66574\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 64.77s | valid accuracy    0.557 | valid loss:   0.727\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.714| loss 0.67423\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.523| loss 0.67143\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.637| loss 0.62323\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 63.46s | valid accuracy    0.589 | valid loss:   0.778\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.733| loss 0.66150\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.604| loss 0.60801\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.700| loss 0.55217\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 63.47s | valid accuracy    0.614 | valid loss:   0.747\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.758| loss 0.65945\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.649| loss 0.56057\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.731| loss 0.52300\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 63.55s | valid accuracy    0.626 | valid loss:   0.757\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.771| loss 0.64517\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.673| loss 0.54549\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.748| loss 0.49011\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 63.67s | valid accuracy    0.642 | valid loss:   0.748\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.778| loss 0.62613\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.695| loss 0.52046\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.760| loss 0.47217\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 63.56s | valid accuracy    0.651 | valid loss:   0.740\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.787| loss 0.61230\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.709| loss 0.50130\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.770| loss 0.46020\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 63.47s | valid accuracy    0.657 | valid loss:   0.735\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.794| loss 0.58938\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.722| loss 0.50365\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.780| loss 0.44977\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 63.49s | valid accuracy    0.662 | valid loss:   0.744\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.798| loss 0.56765\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.732| loss 0.48531\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.788| loss 0.43849\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 63.39s | valid accuracy    0.665 | valid loss:   0.752\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.803| loss 0.55451\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.742| loss 0.47607\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.796| loss 0.42723\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 63.43s | valid accuracy    0.664 | valid loss:   0.788\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  11 |   300/  952 batches | accuracy    0.807| loss 0.52670\n",
            "| epoch  11 |   600/  952 batches | accuracy    0.750| loss 0.46469\n",
            "| epoch  11 |   900/  952 batches | accuracy    0.803| loss 0.41275\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  11 | time: 62.96s | valid accuracy    0.665 | valid loss:   0.819\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.665457083042568  - F1-score:  0.6611045161892226  - Recall: 0.664597575687494\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_LRNN_Sum_cs, metrics_LRNN_Sum_cs = train_loop(\n",
        "           lambda **pp:  LRNN(n_output=2, merging_mode = Merg_Mode.SUM, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20,  \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001},\n",
        "           scheduler_parr = {'step_size': 8, 'gamma':.1},\n",
        "           early_stop_patience = 4 ,\n",
        "           verbose=True\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yPPO3GWlN76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae0dfc2-900d-475f-f5f7-4af62dab4d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.744| loss 0.68596\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.370| loss 0.68802\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.545| loss 0.65744\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 64.08s | valid accuracy    0.558 | valid loss:   0.725\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.715| loss 0.66468\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.521| loss 0.66183\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.643| loss 0.58886\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 62.94s | valid accuracy    0.598 | valid loss:   0.736\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.739| loss 0.66066\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.607| loss 0.61434\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.705| loss 0.54012\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 62.71s | valid accuracy    0.623 | valid loss:   0.722\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.763| loss 0.66219\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.652| loss 0.58728\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.730| loss 0.49416\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 63.05s | valid accuracy    0.636 | valid loss:   0.725\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.773| loss 0.64997\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.673| loss 0.56400\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.745| loss 0.47851\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 62.75s | valid accuracy    0.651 | valid loss:   0.705\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.780| loss 0.63390\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.692| loss 0.53964\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.757| loss 0.46993\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 63.18s | valid accuracy    0.661 | valid loss:   0.683\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.786| loss 0.62100\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.707| loss 0.52009\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.768| loss 0.45532\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 63.09s | valid accuracy    0.664 | valid loss:   0.668\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.792| loss 0.59869\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.721| loss 0.50510\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.776| loss 0.44213\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 62.78s | valid accuracy    0.670 | valid loss:   0.665\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.796| loss 0.57918\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.732| loss 0.48606\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.785| loss 0.43635\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 63.24s | valid accuracy    0.671 | valid loss:   0.670\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.802| loss 0.55006\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.742| loss 0.46871\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.794| loss 0.42160\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 63.18s | valid accuracy    0.673 | valid loss:   0.694\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  11 |   300/  952 batches | accuracy    0.807| loss 0.52662\n",
            "| epoch  11 |   600/  952 batches | accuracy    0.748| loss 0.46140\n",
            "| epoch  11 |   900/  952 batches | accuracy    0.802| loss 0.41417\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  11 | time: 63.58s | valid accuracy    0.673 | valid loss:   0.713\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  12 |   300/  952 batches | accuracy    0.813| loss 0.51201\n",
            "| epoch  12 |   600/  952 batches | accuracy    0.754| loss 0.45320\n",
            "| epoch  12 |   900/  952 batches | accuracy    0.810| loss 0.38496\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  12 | time: 63.81s | valid accuracy    0.672 | valid loss:   0.755\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6715980460572226  - F1-score:  0.6708656022967503  - Recall: 0.6712652454584854\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_LRNN_Mean_cs, metrics_LRNN_Mean_cs = train_loop(\n",
        "           lambda **pp:  LRNN(n_output=2, merging_mode = Merg_Mode.MEAN, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20,  \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001},\n",
        "           scheduler_parr = {'step_size': 8, 'gamma':.1},\n",
        "           early_stop_patience = 4 ,\n",
        "           verbose=True\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDXFcaUTlN76"
      },
      "source": [
        "#### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCzVQlqrlN76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2f3502-ec65-4228-902b-ab8a764071e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LRNN Mean    | Validation F1-score macro: 0.6633057679611347\n",
            "Model: LRNN Concat  | Validation F1-score macro: 0.6611045161892226\n",
            "Model: LRNN Sum     | Validation F1-score macro: 0.6708656022967503\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model: LRNN Mean    | Validation F1-score macro: {metrics_LRNN_Concat_cs['f1_score']}\")\n",
        "print(f\"Model: LRNN Concat  | Validation F1-score macro: {metrics_LRNN_Sum_cs['f1_score']}\")\n",
        "print(f\"Model: LRNN Sum     | Validation F1-score macro: {metrics_LRNN_Mean_cs['f1_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbvTbnP8YUBb"
      },
      "source": [
        "### MRNN architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7nb8DtOlN76"
      },
      "source": [
        "#### Trainings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "2Lp3ZOBCYUBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7cadf8a-0beb-4b0a-fddc-3f23197bce7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.749| loss 0.68857\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.365| loss 0.68217\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.580| loss 0.63167\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 64.97s | valid accuracy    0.614 | valid loss:   0.695\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.724| loss 0.65717\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.561| loss 0.62952\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.678| loss 0.55228\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 63.55s | valid accuracy    0.641 | valid loss:   0.653\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.744| loss 0.63538\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.626| loss 0.57806\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.715| loss 0.50070\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 65.48s | valid accuracy    0.659 | valid loss:   0.632\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.761| loss 0.63196\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.660| loss 0.54735\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.733| loss 0.46782\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 66.12s | valid accuracy    0.667 | valid loss:   0.627\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.770| loss 0.61492\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.683| loss 0.53208\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.746| loss 0.46363\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 66.42s | valid accuracy    0.673 | valid loss:   0.627\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.779| loss 0.60512\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.700| loss 0.50549\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.760| loss 0.46282\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 64.89s | valid accuracy    0.677 | valid loss:   0.636\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.785| loss 0.58997\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.714| loss 0.47084\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.770| loss 0.47949\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 64.94s | valid accuracy    0.682 | valid loss:   0.653\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.790| loss 0.57297\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.727| loss 0.44712\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.780| loss 0.47894\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 63.41s | valid accuracy    0.683 | valid loss:   0.667\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.683182135380321  - F1-score:  0.6824458883756165  - Recall: 0.6828422953250299\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_MRNN_Concat_cs, metrics_MRNN_Concat_cs = train_loop(\n",
        "           lambda **pp:  MRNN(n_output=2, merging_mode = Merg_Mode.CONCAT, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20, \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001},\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 3 ,\n",
        "           verbose=True\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_plots(metrics_MRNN_Concat_cs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "CRKtJsMHh4Tf",
        "outputId": "f7fbc998-dcb5-4151-ab69-1be2a99812d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcDAkpEuYUBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b488daa-199a-46a1-fc34-3a30b99aefcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.738| loss 0.69132\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.360| loss 0.69482\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.527| loss 0.67739\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 63.36s | valid accuracy    0.573 | valid loss:   0.697\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.723| loss 0.66680\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.476| loss 0.68016\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.611| loss 0.64075\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 64.13s | valid accuracy    0.612 | valid loss:   0.666\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.730| loss 0.65096\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.581| loss 0.64708\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.680| loss 0.57726\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 63.45s | valid accuracy    0.633 | valid loss:   0.677\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.745| loss 0.63035\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.625| loss 0.61420\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.708| loss 0.54882\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 64.01s | valid accuracy    0.642 | valid loss:   0.708\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.760| loss 0.61149\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.654| loss 0.58359\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.726| loss 0.51733\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 63.58s | valid accuracy    0.649 | valid loss:   0.706\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.770| loss 0.59818\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.674| loss 0.57192\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.742| loss 0.50838\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 63.39s | valid accuracy    0.653 | valid loss:   0.719\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.776| loss 0.58577\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.690| loss 0.54098\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.752| loss 0.48301\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 63.75s | valid accuracy    0.658 | valid loss:   0.717\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.782| loss 0.57430\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.706| loss 0.51550\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.764| loss 0.46213\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 63.60s | valid accuracy    0.664 | valid loss:   0.729\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.787| loss 0.56047\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.716| loss 0.49451\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.773| loss 0.47043\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 63.40s | valid accuracy    0.664 | valid loss:   0.777\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.793| loss 0.53959\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.726| loss 0.49062\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.781| loss 0.46945\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 63.72s | valid accuracy    0.663 | valid loss:   0.826\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  11 |   300/  952 batches | accuracy    0.798| loss 0.52404\n",
            "| epoch  11 |   600/  952 batches | accuracy    0.736| loss 0.47686\n",
            "| epoch  11 |   900/  952 batches | accuracy    0.791| loss 0.46892\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  11 | time: 63.39s | valid accuracy    0.667 | valid loss:   0.827\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6672714584787159  - F1-score:  0.6639999672681769  - Recall: 0.666528655407483\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_MRNN_Sum_cs, metrics_MRNN_Sum_cs = train_loop(\n",
        "           lambda **pp:  MRNN(n_output=2, merging_mode = Merg_Mode.SUM, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20,  \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001},\n",
        "           scheduler_parr = {'step_size': 8, 'gamma':.1},\n",
        "           early_stop_patience = 4 ,\n",
        "           verbose=True\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3R5NOmmlN77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86347529-4a43-4a2f-ac97-cb364065b4dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.775| loss 0.69219\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.357| loss 0.69375\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.510| loss 0.67662\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 63.92s | valid accuracy    0.577 | valid loss:   0.698\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.726| loss 0.67795\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.485| loss 0.67357\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.627| loss 0.62277\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 64.21s | valid accuracy    0.624 | valid loss:   0.664\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.738| loss 0.64200\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.594| loss 0.62825\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.689| loss 0.56306\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 63.92s | valid accuracy    0.641 | valid loss:   0.670\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.752| loss 0.60923\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.635| loss 0.59112\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.714| loss 0.52338\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 63.87s | valid accuracy    0.656 | valid loss:   0.659\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.760| loss 0.60174\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.662| loss 0.56957\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.729| loss 0.48297\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 64.05s | valid accuracy    0.662 | valid loss:   0.661\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.771| loss 0.59333\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.684| loss 0.53756\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.745| loss 0.46931\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 64.17s | valid accuracy    0.670 | valid loss:   0.663\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.780| loss 0.56751\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.698| loss 0.53001\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.755| loss 0.46798\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 63.85s | valid accuracy    0.673 | valid loss:   0.668\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.786| loss 0.54423\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.713| loss 0.50717\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.768| loss 0.46584\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 64.03s | valid accuracy    0.676 | valid loss:   0.675\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6755059316120028  - F1-score:  0.6736797616310103  - Recall: 0.6749535239584793\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_MRNN_Mean_cs, metrics_MRNN_Mean_cs = train_loop(\n",
        "           lambda **pp:  MRNN(n_output=2, merging_mode = Merg_Mode.MEAN, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20,  \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001},\n",
        "           scheduler_parr = {'step_size': 8, 'gamma':.1},\n",
        "           early_stop_patience = 4 ,\n",
        "           verbose=True\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d59p7aMxlN77"
      },
      "source": [
        "#### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTf6ygVrlN77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b18faac-cdfd-49b9-f967-93d2b58d3676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: MRNN Concat   | Validation F1-score macro: 0.6824458883756165\n",
            "Model: MRNN Sum      | Validation F1-score macro: 0.6639999672681769\n",
            "Model: MRNN Mean     | Validation F1-score macro: 0.6736797616310103\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model: MRNN Concat   | Validation F1-score macro: {metrics_MRNN_Concat_cs['f1_score']}\")\n",
        "print(f\"Model: MRNN Sum      | Validation F1-score macro: {metrics_MRNN_Sum_cs['f1_score']}\")\n",
        "print(f\"Model: MRNN Mean     | Validation F1-score macro: {metrics_MRNN_Mean_cs['f1_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNYe1_PLYUBc"
      },
      "source": [
        "### MLP architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxjfoQvBlN78"
      },
      "source": [
        "#### Trainings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv-Sho_QlN78"
      },
      "outputs": [],
      "source": [
        "MLP_train_dataloader,MLP_val_dataloader= \\\n",
        "  (DataLoader(_, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Define_padding(\"global\")) for _ in datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtMtI-rklN78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b107fd07-c3e8-4f23-8f0e-7f5a3fe2fc70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.744| loss 0.65976\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.542| loss 0.62808\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.643| loss 0.62809\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 38.51s | valid accuracy    0.601 | valid loss:   0.713\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.744| loss 0.59906\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.625| loss 0.56408\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.708| loss 0.55394\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 38.10s | valid accuracy    0.621 | valid loss:   0.737\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.769| loss 0.57282\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.679| loss 0.51914\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.753| loss 0.50452\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 38.06s | valid accuracy    0.623 | valid loss:   0.797\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.794| loss 0.52580\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.727| loss 0.48274\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.790| loss 0.49705\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 39.93s | valid accuracy    0.635 | valid loss:   0.774\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.813| loss 0.49298\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.764| loss 0.43433\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.818| loss 0.47569\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 42.50s | valid accuracy    0.647 | valid loss:   0.726\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.834| loss 0.44821\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.800| loss 0.38558\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.843| loss 0.41490\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 42.94s | valid accuracy    0.652 | valid loss:   0.723\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.853| loss 0.40213\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.833| loss 0.28717\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.856| loss 0.39087\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 38.36s | valid accuracy    0.648 | valid loss:   0.969\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.871| loss 0.35678\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.858| loss 0.28271\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.873| loss 0.33857\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 38.63s | valid accuracy    0.638 | valid loss:   1.141\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.884| loss 0.32946\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.879| loss 0.20482\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.888| loss 0.31171\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 38.13s | valid accuracy    0.617 | valid loss:   1.695\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.898| loss 0.30656\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.897| loss 0.16160\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.902| loss 0.27936\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 39.01s | valid accuracy    0.619 | valid loss:   1.695\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6192602930914166  - F1-score:  0.5798268241930213  - Recall: 0.6168622122704853\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_MLP_Concat_cs, metrics_MLP_Concat_cs = train_loop(\n",
        "           lambda **pp:  MLP(n_output=2, merging_mode = Merg_Mode.CONCAT, cs=True, **pp).to(DEVICE),\n",
        "           MLP_train_dataloader,\n",
        "           MLP_val_dataloader,\n",
        "           epochs=15,\n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001}, \n",
        "           verbose=True,\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 4\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sL9jzBulN78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173d4cac-e00d-4cd8-8c00-f22935f71cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.750| loss 0.66900\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.508| loss 0.66043\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.634| loss 0.61544\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 42.67s | valid accuracy    0.601 | valid loss:   0.713\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.737| loss 0.59804\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.619| loss 0.58748\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.701| loss 0.54943\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 44.91s | valid accuracy    0.618 | valid loss:   0.727\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.758| loss 0.58250\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.664| loss 0.54052\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.741| loss 0.53272\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 39.12s | valid accuracy    0.625 | valid loss:   0.779\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.781| loss 0.54357\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.700| loss 0.49668\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.768| loss 0.51636\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 39.27s | valid accuracy    0.635 | valid loss:   0.763\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.797| loss 0.49198\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.731| loss 0.45426\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.790| loss 0.52166\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 37.70s | valid accuracy    0.638 | valid loss:   0.839\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.813| loss 0.47824\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.760| loss 0.42869\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.807| loss 0.45782\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 37.60s | valid accuracy    0.652 | valid loss:   0.775\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.828| loss 0.47956\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.786| loss 0.36005\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.823| loss 0.38728\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 37.59s | valid accuracy    0.649 | valid loss:   0.857\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.839| loss 0.45695\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.805| loss 0.29597\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.836| loss 0.35124\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 37.90s | valid accuracy    0.641 | valid loss:   1.164\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.854| loss 0.40403\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.824| loss 0.24024\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.850| loss 0.45678\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 39.56s | valid accuracy    0.625 | valid loss:   1.418\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.865| loss 0.36698\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.836| loss 0.22601\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.861| loss 0.42406\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 38.03s | valid accuracy    0.644 | valid loss:   1.269\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  11 |   300/  952 batches | accuracy    0.876| loss 0.35539\n",
            "| epoch  11 |   600/  952 batches | accuracy    0.853| loss 0.21194\n",
            "| epoch  11 |   900/  952 batches | accuracy    0.866| loss 0.32628\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  11 | time: 38.11s | valid accuracy    0.656 | valid loss:   1.036\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  12 |   300/  952 batches | accuracy    0.885| loss 0.30662\n",
            "| epoch  12 |   600/  952 batches | accuracy    0.865| loss 0.18614\n",
            "| epoch  12 |   900/  952 batches | accuracy    0.881| loss 0.30512\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  12 | time: 38.41s | valid accuracy    0.659 | valid loss:   1.185\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  13 |   300/  952 batches | accuracy    0.891| loss 0.29718\n",
            "| epoch  13 |   600/  952 batches | accuracy    0.877| loss 0.14375\n",
            "| epoch  13 |   900/  952 batches | accuracy    0.885| loss 0.31863\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  13 | time: 38.37s | valid accuracy    0.639 | valid loss:   1.829\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  14 |   300/  952 batches | accuracy    0.897| loss 0.27404\n",
            "| epoch  14 |   600/  952 batches | accuracy    0.891| loss 0.15297\n",
            "| epoch  14 |   900/  952 batches | accuracy    0.893| loss 0.28656\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  14 | time: 38.67s | valid accuracy    0.650 | valid loss:   1.782\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  15 |   300/  952 batches | accuracy    0.859| loss 0.33571\n",
            "| epoch  15 |   600/  952 batches | accuracy    0.853| loss 0.18606\n",
            "| epoch  15 |   900/  952 batches | accuracy    0.889| loss 0.29084\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  15 | time: 38.38s | valid accuracy    0.654 | valid loss:   1.500\n",
            "-------------------------------------------------------------------------------------\n",
            "Val_accuracy:  0.6540125610607118  - F1-score:  0.644198022380305  - Recall: 0.6527326073476172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_MLP_Mean_cs, metrics_MLP_Mean_cs = train_loop(\n",
        "           lambda **pp:  MLP(n_output=2, merging_mode = Merg_Mode.MEAN, cs=True, **pp).to(DEVICE),\n",
        "           MLP_train_dataloader,\n",
        "           MLP_val_dataloader,\n",
        "           epochs=15,\n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001}, \n",
        "           verbose=True,\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 4\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ugoeHzUlN78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293709c9-19cb-44d2-98ef-730e656616b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.740| loss 0.66790\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.534| loss 0.64691\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.639| loss 0.61560\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 38.26s | valid accuracy    0.603 | valid loss:   0.718\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.740| loss 0.60793\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.621| loss 0.57606\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.702| loss 0.57943\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 39.78s | valid accuracy    0.624 | valid loss:   0.720\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.764| loss 0.57085\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.666| loss 0.52536\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.742| loss 0.52572\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 39.52s | valid accuracy    0.628 | valid loss:   0.789\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.785| loss 0.54424\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.707| loss 0.49102\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.778| loss 0.49634\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 38.27s | valid accuracy    0.634 | valid loss:   0.830\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.804| loss 0.50860\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.744| loss 0.44455\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.800| loss 0.51669\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 38.24s | valid accuracy    0.638 | valid loss:   0.777\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.822| loss 0.46505\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.776| loss 0.40737\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.825| loss 0.46360\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 38.21s | valid accuracy    0.650 | valid loss:   0.686\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.835| loss 0.45310\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.807| loss 0.36104\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.840| loss 0.38585\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 38.22s | valid accuracy    0.647 | valid loss:   0.866\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.850| loss 0.44244\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.830| loss 0.30531\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.854| loss 0.36413\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 38.15s | valid accuracy    0.635 | valid loss:   1.248\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.866| loss 0.41677\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.853| loss 0.23595\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.864| loss 0.32330\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 38.22s | valid accuracy    0.628 | valid loss:   1.586\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.881| loss 0.39133\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.872| loss 0.18190\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.876| loss 0.32852\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 38.07s | valid accuracy    0.629 | valid loss:   1.640\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6293091416608514  - F1-score:  0.5943643661071425  - Recall: 0.6270138514110031\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_MLP_Sum_cs, metrics_MLP_Sum_cs = train_loop(\n",
        "           lambda **pp:  MLP(n_output=2, merging_mode = Merg_Mode.SUM, cs=True, **pp).to(DEVICE),\n",
        "           MLP_train_dataloader,\n",
        "           MLP_val_dataloader,\n",
        "           epochs=15,\n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001}, \n",
        "           verbose=True,\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 4\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnEzgGzxlN78"
      },
      "source": [
        "#### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNB8L7iBlN79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2327c23f-8840-4d32-a288-422e6fc93622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: MLP Concat  | Validation F1-score macro: 0.5798268241930213\n",
            "Model: MLP Sum     | Validation F1-score macro: 0.5943643661071425\n",
            "Model: MLP Mean    | Validation F1-score macro: 0.644198022380305\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model: MLP Concat  | Validation F1-score macro: {metrics_MLP_Concat_cs['f1_score']}\")\n",
        "print(f\"Model: MLP Sum     | Validation F1-score macro: {metrics_MLP_Sum_cs['f1_score']}\")\n",
        "print(f\"Model: MLP Mean    | Validation F1-score macro: {metrics_MLP_Mean_cs['f1_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU9aOLZFYUBg"
      },
      "source": [
        "### ME architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNK1Sek_lN79"
      },
      "source": [
        "#### Trainings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Iw0BbWAMlN79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c04ecab-d9cc-4db7-9c5c-a39acc476066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.770| loss 0.68642\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.366| loss 0.69342\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.542| loss 0.66292\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 23.98s | valid accuracy    0.577 | valid loss:   0.707\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.731| loss 0.68008\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.503| loss 0.66452\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.617| loss 0.62024\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 24.67s | valid accuracy    0.627 | valid loss:   0.686\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.724| loss 0.66540\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.582| loss 0.63520\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.664| loss 0.57280\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 23.81s | valid accuracy    0.644 | valid loss:   0.674\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.729| loss 0.66645\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.623| loss 0.59951\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.691| loss 0.51145\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 23.42s | valid accuracy    0.649 | valid loss:   0.676\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.744| loss 0.63484\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.649| loss 0.56963\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.710| loss 0.48084\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 23.32s | valid accuracy    0.657 | valid loss:   0.673\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.757| loss 0.63058\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.669| loss 0.55226\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.727| loss 0.46537\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 23.31s | valid accuracy    0.661 | valid loss:   0.672\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.765| loss 0.63126\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.685| loss 0.52616\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.740| loss 0.44834\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 23.35s | valid accuracy    0.665 | valid loss:   0.675\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.774| loss 0.61193\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.698| loss 0.51797\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.751| loss 0.41813\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 23.39s | valid accuracy    0.668 | valid loss:   0.674\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.779| loss 0.63535\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.709| loss 0.49881\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.760| loss 0.40590\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 23.43s | valid accuracy    0.669 | valid loss:   0.676\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.785| loss 0.62002\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.716| loss 0.49145\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.768| loss 0.39510\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 23.57s | valid accuracy    0.668 | valid loss:   0.680\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  11 |   300/  952 batches | accuracy    0.790| loss 0.61898\n",
            "| epoch  11 |   600/  952 batches | accuracy    0.723| loss 0.49780\n",
            "| epoch  11 |   900/  952 batches | accuracy    0.773| loss 0.40036\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  11 | time: 23.48s | valid accuracy    0.669 | valid loss:   0.681\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  12 |   300/  952 batches | accuracy    0.793| loss 0.59717\n",
            "| epoch  12 |   600/  952 batches | accuracy    0.731| loss 0.49099\n",
            "| epoch  12 |   900/  952 batches | accuracy    0.781| loss 0.41759\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  12 | time: 23.43s | valid accuracy    0.669 | valid loss:   0.693\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6693649685973482  - F1-score:  0.6680788760535668  - Recall: 0.668912106087399\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_ME_Concat_cs, metrics_ME_Concat_cs = train_loop(\n",
        "           lambda **pp:  ME(n_output=2, merging_mode = Merg_Mode.CONCAT, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20, \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001}, \n",
        "           verbose=True,\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 4\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PvHqYBE8lN79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fbec83-489d-43cf-f7f0-e3ba47aefc93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.729| loss 0.68803\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.375| loss 0.69657\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.477| loss 0.67924\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 23.29s | valid accuracy    0.537 | valid loss:   0.705\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.752| loss 0.68806\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.396| loss 0.68789\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.520| loss 0.66689\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 23.29s | valid accuracy    0.582 | valid loss:   0.692\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.723| loss 0.67918\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.471| loss 0.68011\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.583| loss 0.63019\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 23.26s | valid accuracy    0.608 | valid loss:   0.672\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.710| loss 0.67607\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.546| loss 0.65710\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.623| loss 0.59895\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 23.30s | valid accuracy    0.621 | valid loss:   0.658\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.710| loss 0.68062\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.588| loss 0.64292\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.653| loss 0.57901\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 23.26s | valid accuracy    0.631 | valid loss:   0.652\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.723| loss 0.65448\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.616| loss 0.61231\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.670| loss 0.54403\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 23.29s | valid accuracy    0.637 | valid loss:   0.651\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.729| loss 0.67735\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.639| loss 0.59388\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.691| loss 0.51987\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 23.26s | valid accuracy    0.640 | valid loss:   0.655\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.740| loss 0.65040\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.652| loss 0.58804\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.703| loss 0.51088\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 23.30s | valid accuracy    0.644 | valid loss:   0.661\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.748| loss 0.66220\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.669| loss 0.58221\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.717| loss 0.46268\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 23.21s | valid accuracy    0.641 | valid loss:   0.667\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch  10 |   300/  952 batches | accuracy    0.753| loss 0.66343\n",
            "| epoch  10 |   600/  952 batches | accuracy    0.681| loss 0.56274\n",
            "| epoch  10 |   900/  952 batches | accuracy    0.727| loss 0.45087\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch  10 | time: 23.18s | valid accuracy    0.642 | valid loss:   0.682\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6421493370551291  - F1-score:  0.6406226427614113  - Recall: 0.6416714341394478\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_ME_Mean_cs, metrics_ME_Mean_cs = train_loop(\n",
        "           lambda **pp:  ME(n_output=2, merging_mode = Merg_Mode.MEAN, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20, \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001}, \n",
        "           verbose=True,\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 4\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UjmjgMqllN79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b710f99-014b-4a6d-b578-9dcbc35782e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   300/  952 batches | accuracy    0.762| loss 0.69549\n",
            "| epoch   1 |   600/  952 batches | accuracy    0.363| loss 0.69095\n",
            "| epoch   1 |   900/  952 batches | accuracy    0.507| loss 0.68018\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   1 | time: 23.23s | valid accuracy    0.555 | valid loss:   0.706\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   2 |   300/  952 batches | accuracy    0.740| loss 0.68484\n",
            "| epoch   2 |   600/  952 batches | accuracy    0.422| loss 0.68704\n",
            "| epoch   2 |   900/  952 batches | accuracy    0.559| loss 0.66172\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   2 | time: 23.28s | valid accuracy    0.593 | valid loss:   0.691\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   3 |   300/  952 batches | accuracy    0.720| loss 0.67792\n",
            "| epoch   3 |   600/  952 batches | accuracy    0.509| loss 0.66242\n",
            "| epoch   3 |   900/  952 batches | accuracy    0.608| loss 0.62653\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   3 | time: 23.23s | valid accuracy    0.611 | valid loss:   0.666\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   4 |   300/  952 batches | accuracy    0.711| loss 0.68633\n",
            "| epoch   4 |   600/  952 batches | accuracy    0.567| loss 0.64554\n",
            "| epoch   4 |   900/  952 batches | accuracy    0.640| loss 0.58074\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   4 | time: 23.28s | valid accuracy    0.620 | valid loss:   0.647\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   5 |   300/  952 batches | accuracy    0.716| loss 0.67969\n",
            "| epoch   5 |   600/  952 batches | accuracy    0.602| loss 0.63367\n",
            "| epoch   5 |   900/  952 batches | accuracy    0.662| loss 0.56759\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   5 | time: 23.21s | valid accuracy    0.627 | valid loss:   0.640\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   6 |   300/  952 batches | accuracy    0.727| loss 0.69060\n",
            "| epoch   6 |   600/  952 batches | accuracy    0.625| loss 0.60516\n",
            "| epoch   6 |   900/  952 batches | accuracy    0.683| loss 0.51897\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   6 | time: 23.24s | valid accuracy    0.636 | valid loss:   0.641\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   7 |   300/  952 batches | accuracy    0.736| loss 0.69085\n",
            "| epoch   7 |   600/  952 batches | accuracy    0.648| loss 0.58764\n",
            "| epoch   7 |   900/  952 batches | accuracy    0.699| loss 0.50520\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   7 | time: 23.28s | valid accuracy    0.638 | valid loss:   0.645\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   8 |   300/  952 batches | accuracy    0.748| loss 0.69479\n",
            "| epoch   8 |   600/  952 batches | accuracy    0.665| loss 0.58073\n",
            "| epoch   8 |   900/  952 batches | accuracy    0.713| loss 0.48126\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   8 | time: 23.23s | valid accuracy    0.644 | valid loss:   0.657\n",
            "-------------------------------------------------------------------------------------\n",
            "| epoch   9 |   300/  952 batches | accuracy    0.753| loss 0.68088\n",
            "| epoch   9 |   600/  952 batches | accuracy    0.676| loss 0.54765\n",
            "| epoch   9 |   900/  952 batches | accuracy    0.725| loss 0.43723\n",
            "-------------------------------------------------------------------------------------\n",
            "  | end of epoch   9 | time: 23.25s | valid accuracy    0.646 | valid loss:   0.659\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            " === Early Stopping ===\n",
            "\n",
            "Val_accuracy:  0.6459176552686672  - F1-score:  0.6455065476917261  - Recall: 0.6456876046383003\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_ME_Sum_cs, metrics_ME_Sum_cs = train_loop(\n",
        "           lambda **pp:  ME(n_output=2, merging_mode = Merg_Mode.SUM, cs=True, **pp).to(DEVICE),\n",
        "           train_dataloader, \n",
        "           val_dataloader, \n",
        "           epochs=20, \n",
        "           criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHTS).to(DEVICE)),\n",
        "           params = {'hidden': 128, 'LR_Adam': 0.0001}, \n",
        "           verbose=True,\n",
        "           scheduler_parr = {'step_size': 6, 'gamma':.1},\n",
        "           early_stop_patience = 4\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFRA30aGlN7-"
      },
      "source": [
        "#### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLArsSOvlN7-"
      },
      "outputs": [],
      "source": [
        "print(f\"Model: ME Mean    | Validation F1-score macro: {metrics_ME_Concat_cs['f1_score']}\")\n",
        "print(f\"Model: ME Concat  | Validation F1-score macro: {metrics_ME_Sum_cs['f1_score']}\")\n",
        "print(f\"Model: ME Sum     | Validation F1-score macro: {metrics_ME_Mean_cs['f1_score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7loV6Giqvei"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the results that we obtained, and after a comparison made on the validation set, the best model architecture turned out to be the MRNN model with the concatenation merging mode. We apply the final evaluation on this model."
      ],
      "metadata": {
        "id": "Fn4ISd6SV3G4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "g8B1XrMglN7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e75c0d-03d5-4cbc-bdaf-cf1dfa16343b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights matrix size: (44461, 200)\n"
          ]
        }
      ],
      "source": [
        "ENCODED_TEST_DF = apply_conversion(TEST_DF, WORD_TO_POSITION_DD)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    CustomTextDataset(ENCODED_TEST_DF),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=Define_padding()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We update the embedding matrix with the OOV terms coming from the test set\n",
        "model_MRNN_Concat_cs.update_embedding(np.concatenate([model_MRNN_Concat_cs.embedding.weight.cpu().detach().numpy(),\\\n",
        "                                          WEIGHT_MATRIX[model_MRNN_Concat_cs.embedding.weight.size(0):,:]]))\n"
      ],
      "metadata": {
        "id": "N-op7-WWmaRL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWwfnD7ukAEi"
      },
      "source": [
        "### Multi-input classification evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_accuracy, labels_and_pred_accum = evaluate(test_dataloader, model_MRNN_Concat_cs.cuda(), retain=True)\n",
        "\n",
        "print(\"Model: MRNN with concatenation merging mode:\")\n",
        "print(f\"Test F1-score: {get_f1_score(labels_and_pred_accum)} | Test accuracy: {test_accuracy}\")\n",
        "print(f\"Test Precision: {get_precision(labels_and_pred_accum)} | Test recall: {get_recall_score(labels_and_pred_accum)}\")\n"
      ],
      "metadata": {
        "id": "rEzEmZ-cUQaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d941e92-b3ba-4888-d105-3c62d482aa28"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: MRNN with concatenation merging mode:\n",
            "Test F1-score: 0.6601177322315155 | Test accuracy: 0.6630963972736125\n",
            "Test Precision: 0.6685089812837584 | Test recall: 0.6628036752712669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ7bjEDOkAEi"
      },
      "source": [
        "###  Claim verification evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "dIgdz6HlkAEi"
      },
      "outputs": [],
      "source": [
        "def Claim_evaluation(dataframe,model,pad=False):\n",
        "  id_unique,id_index,_=np.unique(dataframe['ID'],return_counts=True,return_index=True)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    total=0 \n",
        "    predicted=[]\n",
        "    for i in id_index:\n",
        "      predictions_same_claim=0\n",
        "      evidences=dataframe['Evidence'][dataframe['ID']==dataframe['ID'].iloc[i]]\n",
        "      voted=[]\n",
        "      for j in evidences:\n",
        "        accumulated_good_pred, total_count = 0, 0\n",
        "       \n",
        "        predicted_label = model( tensor(dataframe['Claim'].iloc[i]).reshape((1,-1)), tensor(j).reshape((1,-1)))\n",
        "        voted.append(predicted_label.argmax(1).item())\n",
        "        predictions_same_claim+=(predicted_label.argmax(1)==dataframe['Label'].iloc[i].argmax(0)).sum().item()\n",
        "\n",
        "      a,b=np.unique(voted,return_counts=True)\n",
        "      a=a[np.argmax(b)]\n",
        "      predicted.append(a)\n",
        "\n",
        "      total+=(predictions_same_claim/len(evidences)>0.5)\n",
        "\n",
        "    return total/id_unique.shape[0], predicted, dataframe['Label'][id_index].apply(lambda x: x.argmax(0).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "MinTnJ6RkAEi"
      },
      "outputs": [],
      "source": [
        "accuracy,y_pred,y_true=Claim_evaluation(ENCODED_TEST_DF,model_MRNN_Concat_cs.cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "8bCTpdRfkAEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb9076e-3b37-48b1-eb2c-aa269e630fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: MRNN with concatenation merging mode:\n",
            "Test F1-score: 0.6624353214656651 | Test accuracy: 0.6599122939664298\n",
            "Test Precision: 0.6706918606465081 | Test recall: 0.6651367939956843\n"
          ]
        }
      ],
      "source": [
        "print(\"Model: MRNN with concatenation merging mode:\")\n",
        "print(f\"Test F1-score: {f1_score(y_true, y_pred, average='macro')} | Test accuracy: {accuracy}\")\n",
        "print(f\"Test Precision: {precision_score(y_true, y_pred, average='macro')} | Test recall: {recall_score(y_true, y_pred, average='macro')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vG37wXekAEi"
      },
      "source": [
        "## Error analysis and conclusions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pformat, pprint\n",
        "\n",
        "revert = lambda dict_: { v:k for k,v in dict_.items() }\n",
        "POSITION_TO_WORD = revert(WORD_TO_POSITION_DD)\n"
      ],
      "metadata": {
        "id": "oUtSZwnw06XM"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1WwmHpED7lyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=0\n",
        "for i in ENCODED_TEST_DF.index:\n",
        "  predicted_label=model_MRNN_Concat_cs( tensor(ENCODED_TEST_DF['Claim'].iloc[i]).reshape((1,-1)), tensor(ENCODED_TEST_DF['Evidence'].iloc[i]).reshape((1,-1)))\n",
        "  \n",
        "  if(predicted_label.argmax(1)!=ENCODED_TEST_DF['Label'].iloc[i].argmax(0)):\n",
        "    print(\"CLAIM:\")\n",
        "    print(' '.join([POSITION_TO_WORD[j] for j in ENCODED_TEST_DF['Claim'].iloc[i]])) \n",
        "    print(\"EVIDENCE:\")\n",
        "    print(' '.join([POSITION_TO_WORD[j] for j in ENCODED_TEST_DF['Evidence'].iloc[i]]))\n",
        "    print(\"True Prediction:\")\n",
        "    print(ENCODED_TEST_DF['Label'].iloc[i].argmax(0).item())\n",
        "    print(\"Predicted:\")\n",
        "    print(predicted_label.argmax(1).item())\n",
        "    print()\n",
        "    num+=1\n",
        "    if(num==15):\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QigKFdsz33vE",
        "outputId": "cc1143e8-854d-4fc2-ed89-b87d5bcf05a6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLAIM:\n",
            "firefox application .\n",
            "EVIDENCE:\n",
            "mozilla firefox ( simply firefox ) free open-source web browser developed mozilla foundation subsidiary mozilla corporation . mozilla foundation mozilla foundation mozilla corporation mozilla corporation free open-source free open-source web browser web browser\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n",
            "CLAIM:\n",
            "google search find stock quotes .\n",
            "EVIDENCE:\n",
            "these include synonyms , weather forecasts , time zones , stock quotes , maps , earthquake data , movie showtimes , airports , home listings , sports scores .\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n",
            "CLAIM:\n",
            "a good day die hard directed john moore .\n",
            "EVIDENCE:\n",
            "the film directed john moore written skip woods , stars bruce willis john mcclane . john moore john moore ( director ) skip woods skip woods bruce willis bruce willis john mcclane john mcclane\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n",
            "CLAIM:\n",
            "spider-man 2 released 2004 .\n",
            "EVIDENCE:\n",
            "spider-man 2 2004 american superhero film directed sam raimi written alvin sargent story alfred gough , miles millar , michael chabon . sam raimi sam raimi alvin sargent alvin sargent alfred gough alfred gough miles millar miles millar michael chabon michael chabon spider-man spider-man ( 2002 film ) superhero superhero film\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n",
            "CLAIM:\n",
            "kaya scodelario director .\n",
            "EVIDENCE:\n",
            "kaya scodelario-davis ( born kaya rose humphrey ; march 13 , 1992 ) english actress . english english people\n",
            "True Prediction:\n",
            "0\n",
            "Predicted:\n",
            "1\n",
            "\n",
            "CLAIM:\n",
            "the brat pack appeared together teen-oriented coming-of-age video games .\n",
            "EVIDENCE:\n",
            "the brat pack nickname given group young actors frequently appeared together teen-oriented coming-of-age films 1980 s . coming-of-age films : category : coming-of-age films\n",
            "True Prediction:\n",
            "0\n",
            "Predicted:\n",
            "1\n",
            "\n",
            "CLAIM:\n",
            "antigua barbuda birthplace christopher columbus .\n",
            "EVIDENCE:\n",
            "during first voyage 1492 , reached new world instead arriving japan intended , landing island bahamas archipelago named `` san salvador '' . new world americas japan japan bahamas archipelago the bahamas\n",
            "True Prediction:\n",
            "0\n",
            "Predicted:\n",
            "1\n",
            "\n",
            "CLAIM:\n",
            "kung fu panda made $ 75 million opening weekend .\n",
            "EVIDENCE:\n",
            "kung fu panda opened 4,114 theaters , grossing $ 20 .3 million opening day $ 60 .2 million opening weekend , resulting number one position box office .\n",
            "True Prediction:\n",
            "0\n",
            "Predicted:\n",
            "1\n",
            "\n",
            "CLAIM:\n",
            "uganda ruled british .\n",
            "EVIDENCE:\n",
            "beginning 1894 , area ruled protectorate british , established administrative law across territory .\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n",
            "CLAIM:\n",
            "firefox operating system shell .\n",
            "EVIDENCE:\n",
            "mozilla firefox ( simply firefox ) free open-source web browser developed mozilla foundation subsidiary mozilla corporation . mozilla foundation mozilla foundation mozilla corporation mozilla corporation free open-source free open-source web browser web browser\n",
            "True Prediction:\n",
            "0\n",
            "Predicted:\n",
            "1\n",
            "\n",
            "CLAIM:\n",
            "scandinavia include mountains .\n",
            "EVIDENCE:\n",
            "much scandinavian mountains alpine tundra climate . scandinavian scandinavian people alpine tundra alpine tundra\n",
            "True Prediction:\n",
            "0\n",
            "Predicted:\n",
            "1\n",
            "\n",
            "CLAIM:\n",
            "the quiet released 2005 .\n",
            "EVIDENCE:\n",
            "the quiet 2005 american drama thriller film directed jamie babbit starring camilla belle elisha cuthbert . jamie babbit jamie babbit camilla belle camilla belle elisha cuthbert elisha cuthbert drama drama film thriller film thriller film\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n",
            "CLAIM:\n",
            "honeymoon third major-label record lana del rey .\n",
            "EVIDENCE:\n",
            "honeymoon fourth studio album third major-label record american singer songwriter lana del rey . lana del rey lana del rey studio album studio album\n",
            "True Prediction:\n",
            "0\n",
            "Predicted:\n",
            "1\n",
            "\n",
            "CLAIM:\n",
            "cambridgeshire 's county council council .\n",
            "EVIDENCE:\n",
            "cambridgeshire county council county council cambridgeshire , england . county council county council cambridgeshire cambridgeshire\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n",
            "CLAIM:\n",
            "cambridgeshire 's county council council .\n",
            "EVIDENCE:\n",
            "local government divided cambridgeshire county council peterborough city council , separate unitary authority . cambridgeshire county council cambridgeshire county council peterborough city council peterborough city council unitary authority unitary authorities england\n",
            "True Prediction:\n",
            "1\n",
            "Predicted:\n",
            "0\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_env",
      "language": "python",
      "name": "nlp_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
